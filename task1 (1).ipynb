{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271d57c-a4c7-4dc6-b793-11c8653dee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Internship Task: Human Activity Recognition (HAR) using UCI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22426f03-3a13-48fa-8c0c-f4eae07e7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task 1: Train and Compare Classic ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3046510-b8c3-4899-9063-ad597af347b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a6a502-c25a-41f6-80e4-7793842f74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data files\n",
    "def load_data():\n",
    "    features = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\features.txt', delim_whitespace=True, header=None, names=['index', 'feature'])\n",
    "    activity_labels = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\activity_labels.txt', delim_whitespace=True, header=None, names=['label', 'activity'])\n",
    "    X_train = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\train\\\\X_train.txt', delim_whitespace=True, header=None)\n",
    "    y_train = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\train\\\\y_train.txt', delim_whitespace=True, header=None, names=['label'])\n",
    "    X_test = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\test\\\\X_test.txt', delim_whitespace=True, header=None)\n",
    "    y_test = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\test\\\\y_test.txt', delim_whitespace=True, header=None, names=['label'])\n",
    "    return features, activity_labels, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a68ed49-9de4-4295-9eeb-0ec86df344e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neelp\\AppData\\Local\\Temp\\ipykernel_12600\\298218205.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  features = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\features.txt', delim_whitespace=True, header=None, names=['index', 'feature'])\n",
      "C:\\Users\\neelp\\AppData\\Local\\Temp\\ipykernel_12600\\298218205.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  activity_labels = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\activity_labels.txt', delim_whitespace=True, header=None, names=['label', 'activity'])\n",
      "C:\\Users\\neelp\\AppData\\Local\\Temp\\ipykernel_12600\\298218205.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  X_train = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\train\\\\X_train.txt', delim_whitespace=True, header=None)\n",
      "C:\\Users\\neelp\\AppData\\Local\\Temp\\ipykernel_12600\\298218205.py:6: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y_train = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\train\\\\y_train.txt', delim_whitespace=True, header=None, names=['label'])\n",
      "C:\\Users\\neelp\\AppData\\Local\\Temp\\ipykernel_12600\\298218205.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  X_test = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\test\\\\X_test.txt', delim_whitespace=True, header=None)\n",
      "C:\\Users\\neelp\\AppData\\Local\\Temp\\ipykernel_12600\\298218205.py:8: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y_test = pd.read_csv('C:\\\\Users\\\\neelp\\\\Downloads\\\\human+activity+recognition+using+smartphones\\\\UCI HAR Dataset\\\\UCI HAR Dataset\\\\test\\\\y_test.txt', delim_whitespace=True, header=None, names=['label'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess data\n",
    "features, activity_labels, X_train, y_train, X_test, y_test = load_data()\n",
    "y_train = y_train['label'].map(dict(zip(activity_labels['label'], activity_labels['activity'])))\n",
    "y_test = y_test['label'].map(dict(zip(activity_labels['label'], activity_labels['activity'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c9ab0b-0e6f-48f7-91f9-a424e4a3fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cca463f-84d5-48bb-822a-8a5d26e5d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "--- Random Forest Results ---\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.91      0.89      0.90       491\n",
      "          STANDING       0.90      0.92      0.91       532\n",
      "           WALKING       0.89      0.97      0.93       496\n",
      "WALKING_DOWNSTAIRS       0.97      0.87      0.92       420\n",
      "  WALKING_UPSTAIRS       0.90      0.89      0.89       471\n",
      "\n",
      "          accuracy                           0.93      2947\n",
      "         macro avg       0.93      0.92      0.92      2947\n",
      "      weighted avg       0.93      0.93      0.93      2947\n",
      "\n",
      "==================================================\n",
      "Training Decision Tree...\n",
      "--- Decision Tree Results ---\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.83      0.76      0.80       491\n",
      "          STANDING       0.80      0.86      0.83       532\n",
      "           WALKING       0.83      0.92      0.87       496\n",
      "WALKING_DOWNSTAIRS       0.89      0.83      0.86       420\n",
      "  WALKING_UPSTAIRS       0.83      0.78      0.80       471\n",
      "\n",
      "          accuracy                           0.86      2947\n",
      "         macro avg       0.86      0.86      0.86      2947\n",
      "      weighted avg       0.86      0.86      0.86      2947\n",
      "\n",
      "==================================================\n",
      "Training Logistic Regression...\n",
      "--- Logistic Regression Results ---\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.97      0.88      0.93       491\n",
      "          STANDING       0.90      0.98      0.94       532\n",
      "           WALKING       0.94      0.99      0.97       496\n",
      "WALKING_DOWNSTAIRS       0.99      0.96      0.98       420\n",
      "  WALKING_UPSTAIRS       0.97      0.94      0.96       471\n",
      "\n",
      "          accuracy                           0.96      2947\n",
      "         macro avg       0.96      0.96      0.96      2947\n",
      "      weighted avg       0.96      0.96      0.96      2947\n",
      "\n",
      "==================================================\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neelp\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AdaBoost Results ---\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.00      0.00      0.00       491\n",
      "          STANDING       0.52      1.00      0.68       532\n",
      "           WALKING       0.36      1.00      0.53       496\n",
      "WALKING_DOWNSTAIRS       0.00      0.00      0.00       420\n",
      "  WALKING_UPSTAIRS       0.00      0.00      0.00       471\n",
      "\n",
      "          accuracy                           0.53      2947\n",
      "         macro avg       0.31      0.50      0.37      2947\n",
      "      weighted avg       0.34      0.53      0.39      2947\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neelp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\neelp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\neelp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\neelp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    print(f\"--- {model_name} Results ---\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0556ec52-9ee4-44d7-af60-a050cc846fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n",
      "                      Accuracy  Precision    Recall  F1 Score\n",
      "Random Forest        0.926026   0.927297  0.926026  0.925890\n",
      "Decision Tree        0.862233   0.863273  0.862233  0.861652\n",
      "Logistic Regression  0.960977   0.962296  0.960977  0.960854\n",
      "AdaBoost             0.531049   0.336286  0.531049  0.394408\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Model Comparison:\\n\", results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb0a46f-55cb-4808-9166-8cf43b11263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task 1: Classic Machine Learning Models\n",
    "Objective: Train and compare several machine learning models on the UCI HAR dataset to evaluate their performance.\n",
    "Approach:\n",
    "Loaded the UCI HAR dataset, including feature extraction, data preprocessing, and model training.\n",
    "Models used:\n",
    "Random Forest: Achieved 93% accuracy, with high precision, recall, and F1 scores across all activity classes.\n",
    "Decision Tree: Achieved 86% accuracy, with slightly lower performance in recall for some classes.\n",
    "Logistic Regression: Achieved 96% accuracy, performing well in all metrics (precision, recall, and F1 score).\n",
    "AdaBoost: Achieved 53% accuracy, with poor performance due to class imbalance and model limitations.\n",
    "Results:\n",
    "Best Model: Logistic Regression (96% accuracy, highest F1 score of 0.96)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
